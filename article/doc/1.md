# 浅谈Web Audio API


>  “人生如戏，全靠演技。” “没有声音，再好的戏也出不来。”

过去，网页只能借助Flash，QuikTime等插件播放音频，自从HTML5新增了`audio`标签，网页才原生支持了音频播放。

而Web Audio API弥补了audio标签功能简单的不足（Web Audio API属于Web API的范畴，严格意义上讲并不属于HTML5），提供了大量的功能，能够实现媲美桌面播放器的功能。

### Web Audio API
Web Audio API规范虽然并不多，但是却非常灵活。学习并不难，但是实际使用却有一定的难度。（我不是搞数学的，也不是搞音乐的，所以感觉有一定难度。）

这其中涉及到很多音频处理的知识和专业的英文词汇，外行想要完全搞懂是比较难的。在这以前，我们对音频的处理只限于开始，停止和暂停（尴尬）。现在Web Audio API为我们提供了大量的功能：
1.多种音频输入方式和处理方式
2.路由模组化，能够在输入和输出之构建多级处理模块。
3.丰富的参数调节，包括但不限于采样精度、音频波封、滤波器、低频振荡器等等
4.灵活的分离合并声道处理
5.空间化音频和卷积引擎能够实现各种各样的效果
6.动态高效的时域频谱分析
7.憋说了，你牛逼！

API概览：

| 接口|功能|
| --------   | -----:  |
| AudioContext     | 音频接口上下文对象，包含音频信号的路由图，用来表示AudioNodes之间的连接关系 |
| AudioNodes        |   代表音频的输入、输出以及中间处理的节点或模块。AudioNodes之间可以动态链接在一起   |
| AudioDestinationNode        |    表示所有处理后的音频信号的最终目的地    |
|    AudioBuffer   |   音频缓冲器，表示驻留在内存中的音频内容   |
|    AudioBufferSourceNode   |   由AudioBuffer产生音频的AudioNode   |
|    MediaElementAudioSourceNode   |   来源于audio标签、video标签或其他元素的音频资源   |
|    MediaStreamAudioSourceNode   |   来源于MediaStream的音频资源（常用语现场音频输入或远程输入）   |
|    MediaStreamAudioDestinationNode   |   表示传输到MediaStream的音频信号的最终目的地的节点   |
|   ScriptProcessorNode |    使用JavaScript来处理或者产生音频的节点   |
|   AudioParam |    代表音频相关的参数   |
|   GainNode    |   用于增益控制或者构建混音器   |
|   BiquardFilterNode    |  低阶滤波器节点    |
|   DelayNode    |  可同台调节延迟的节点    |
|   PannerNode    | 调节音频空间定位的节点    |
|   ConvolverNode    |  调节实时线性效果的节点    |
|   AnalyserNode    |   提供实时的频率和时域的信息，用于数据分析和可视化   |
|   ChannelSplitterNode    |    从一个音频源中分离出不同的声道并输出单一声道  |
|   ChannelMergerNode    |   将多个音频流的声道合并为一个流  |
|   DynamicsCompressorNode    |     用于动态压缩的节点 |
|   WaveShaperNode |    代表一个非线性畸变放大器，用来对音频信号进行波形整形    |
|   OscillatorNode |    可以使用指定频率生成正弦波的节点    |


### 路由图

AudioContext中包含了许许多多的几点，大致分为三类：源、目标和中间节点。
一个完整的路由图就是将每个用到的节点以串联的方式一个一个连接起来组成的。其中，源节点和目的节点是必须的。中间节点提供了各式各样的功能和效果。

下图则是一个最简单的路由图：
![image001.png-5.2kB][1]

想让Web Audio API播放音乐并不复杂，只需要将源（source）于目标（destination）连接（connect）起来就可以播放音频了。

更加复杂的功能只需要在中间加入需要的处理模块（节点）即可。
举个栗子：
```javascript
var audioCtx = new (window.AudioContext || window.webkitAudioContext)();

var analyser = audioCtx.createAnalyser();
var distortion = audioCtx.createWaveShaper();
var gainNode = audioCtx.createGain();
var biquadFilter = audioCtx.createBiquadFilter();

source = audioCtx.createMediaStreamSource(stream);//源
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(gainNode);
gainNode.connect(audioCtx.destination); // 目标
```

### 音频可视化
是否还记得曾经Window Media Player的可视化效果？一边播放音乐，一波呈现出眼花缭乱的图像。伴随着节奏，忽高忽低，忽上忽下。

利用Web Audio API和canvas，我们也可以做出类似的效果。其核心是AnalyserNode，不仅仅用来表示实时频率和时域的信息，还可以用来实现音频可视化。

```javascript
var array = new Uint8Array(analyser.frequencyBinCount);
analyser.getByteFrequencyData(array);
```
 这样我们就得得到了一个实时表示频率信息的数组了。之后这些数据可以完美地与canvas配合，画出酷炫的效果。
 
 举个栗子：
 
```javascript
canvasContext.clearRect(0,0,canvas.width,canvas.height);
var w = canvas.width / size ;
for(var i = 0; i < size; i++){
    var h1 = arr[i]/256 * canvas.height;
    var h2 = canvas.height - h1;
    canvasContext.fillRect(w * i, h2, w * 0.6, h1);
}
```

此处可以尽情发挥想象，用Canvas画出各种各样魔性的图案。

### 均衡器和其他音效
Web Auidio API提供了相当丰富的音频处理节点，可以实现我们常见的音效和均衡器效果。由于篇（ben）幅（ren）有（tai）限（lan），这部分内容留到下次再详细讨论 :-D。


  [1]: http://static.zybuluo.com/WilberWei/23g6yugqsimcxtbeg5ivuobu/image001.png